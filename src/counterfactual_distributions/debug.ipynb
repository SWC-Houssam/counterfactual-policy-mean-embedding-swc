{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "#  Distributional Testing under Stochastic Policies with Doubly Robust Kernel Statistic\n",
    "# ==============================\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from scipy.stats import laplace, bernoulli\n",
    "from sklearn.metrics import pairwise_kernels\n",
    "import scipy.stats as st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 1. Define Policy Classes\n",
    "# ==============================\n",
    "class GaussianPolicy:\n",
    "    def __init__(self, w, scale=1.0):\n",
    "        self.w = w\n",
    "        self.scale = scale\n",
    "\n",
    "    def sample_treatments(self, X):\n",
    "        mean = X @ self.w\n",
    "        return np.random.normal(mean, self.scale)\n",
    "\n",
    "    def get_propensities(self, X, t):\n",
    "        mean = X @ self.w\n",
    "        return (1/(self.scale * np.sqrt(2*np.pi))) * np.exp(-0.5*((t-mean)/self.scale)**2)\n",
    "\n",
    "class LaplacePolicy:\n",
    "    def __init__(self, w, scale=0.5):\n",
    "        self.w = w\n",
    "        self.scale = scale\n",
    "\n",
    "    def sample_treatments(self, X):\n",
    "        mean = X @ self.w\n",
    "        return laplace.rvs(loc=mean, scale=self.scale)\n",
    "\n",
    "    def get_propensities(self, X, t):\n",
    "        mean = X @ self.w\n",
    "        return (1/(2*self.scale)) * np.exp(-np.abs(t-mean)/self.scale)\n",
    "\n",
    "\n",
    "class BernoulliPolicy:\n",
    "    def __init__(self, w):\n",
    "        self.w = w\n",
    "\n",
    "    def sample_treatments(self, X):\n",
    "        prob = 1 / (1 + np.exp(-(X @ self.w)))\n",
    "        return 2 * bernoulli.rvs(prob) - 1\n",
    "\n",
    "    def get_propensities(self, X, t):\n",
    "        prob = 1 / (1 + np.exp(-(X @ self.w)))\n",
    "        t = (t + 1) // 2  # map {-1, 1} to {0, 1}\n",
    "        return prob if t == 1 else 1 - prob\n",
    "\n",
    "class EstimatedLoggingPolicy:\n",
    "    def __init__(self, X, T):\n",
    "        if np.issubdtype(T.dtype, np.integer) and np.unique(T).size == 2:\n",
    "            self.model_type = 'binary'\n",
    "            self.model = LogisticRegression()\n",
    "            self.model.fit(X, ((T + 1) // 2))  # map {-1, 1} to {0, 1}\n",
    "        else:\n",
    "            self.model_type = 'continuous'\n",
    "            self.model = LinearRegression()\n",
    "            self.model.fit(X, T)\n",
    "\n",
    "    def get_propensities(self, X, t):\n",
    "        if self.model_type == 'binary':\n",
    "            prob = self.model.predict_proba(X)[:, 1]\n",
    "            t = (t + 1) // 2  # map {-1, 1} to {0, 1}\n",
    "            return prob if t == 1 else 1 - prob\n",
    "        else:\n",
    "            mean = self.model.predict(X)\n",
    "            return (1/np.sqrt(2*np.pi)) * np.exp(-0.5*(t-mean)**2)\n",
    "        \n",
    "# ==============================\n",
    "# 2. Define Outcome Model\n",
    "# ==============================\n",
    "def outcome_model(X, T, beta, gamma):\n",
    "    noise = 0.1 * np.random.randn(len(T))\n",
    "    return X @ beta + gamma * T + noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.array([0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "gamma = 1.0\n",
    "\n",
    "w0 = np.random.randn(len(beta))\n",
    "w = np.random.randn(len(beta))\n",
    "w_prime = np.random.randn(len(beta))\n",
    "\n",
    "sample_sizes = [50, 100, 200, 250, 300, 350]\n",
    "num_experiments = 200\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# Scenario i) No Treatment Effect\n",
    "logging_pi = GaussianPolicy(w0)\n",
    "pi = GaussianPolicy(w)\n",
    "pi_prime = GaussianPolicy(w, scale=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = 200\n",
    "X = np.random.randn(ns, len(beta))\n",
    "X_prime = np.random.randn(ns, len(beta))\n",
    "\n",
    "logging_T = logging_pi.sample_treatments(X)\n",
    "logging_propensities = logging_pi.get_propensities(X, logging_T)\n",
    "logging_Y = outcome_model(X, logging_T, beta, gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# T_pi = pi.sample_treatments(X)\n",
    "# T_pi_prime = pi_prime.sample_treatments(X_prime)\n",
    "# Y_pi = outcome_model(X, T_pi, beta, gamma)\n",
    "# Y_pi_prime = outcome_model(X_prime, T_pi_prime, beta, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from sys import stdout\n",
    "from sklearn.metrics import pairwise_kernels\n",
    "import scipy.stats as st\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# Code extracted from https://github.com/sorawitj/counterfactual-mean-embedding/\n",
    "\n",
    "def MMD2u(K, w, m, n):\n",
    "    \"\"\"The MMD^2_u unbiased statistic.\n",
    "    \"\"\"\n",
    "    # wx = 1.0/np.array(w[:m])[:,np.newaxis]\n",
    "    # wy = 1.0/np.array(1.0 - w[m:])[:,np.newaxis]\n",
    "\n",
    "    w_pi = w[:m]\n",
    "    w_pi_prime = w[m:]\n",
    "    K_pi = np.outer(w_pi,w_pi)*K[:m, :m]\n",
    "    K_pi_prime = np.outer(w_pi_prime,w_pi_prime)*K[m:, m:]\n",
    "    K_pi_pi_prime = np.outer(w_pi,w_pi_prime)*K[:m, m:]\n",
    "\n",
    "    return 1.0 / (m * (m - 1.0)) * (K_pi.sum() - K_pi.diagonal().sum()) + \\\n",
    "        1.0 / (n * (n - 1.0)) * (K_pi_prime.sum() - K_pi_prime.diagonal().sum()) - \\\n",
    "        2.0 / (m * n) * K_pi_pi_prime.sum()\n",
    "\n",
    "\n",
    "def compute_null_distribution(K, w, m, n, \n",
    "                              iterations=10000, verbose=False,\n",
    "                              random_state=None, marker_interval=1000):\n",
    "    \"\"\"Compute the bootstrap null-distribution of MMD2u.\n",
    "    \"\"\"\n",
    "    if type(random_state) == type(np.random.RandomState()):\n",
    "        rng = random_state\n",
    "    else:\n",
    "        rng = np.random.RandomState(random_state)\n",
    "\n",
    "    mmd2u_null = np.zeros(iterations)\n",
    "    for i in range(iterations):\n",
    "        if verbose and (i % marker_interval) == 0:\n",
    "            print(i),\n",
    "            stdout.flush()\n",
    "        idx = rng.permutation(m+n)\n",
    "        K_i = K[idx, idx[:, None]]\n",
    "        w_i = w[idx]\n",
    "        mmd2u_null[i] = MMD2u(K_i, w_i, m, n)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\")\n",
    "\n",
    "    return mmd2u_null\n",
    "\n",
    "\n",
    "def kernel_two_sample_test_nonuniform(Y, w, m, n, kernel_function='rbf', iterations=500,\n",
    "                           verbose=False, random_state=None, **kwargs):\n",
    "    \"\"\"Compute MMD^2_u, its null distribution and the p-value of the\n",
    "    kernel two-sample test.\n",
    "    Note that extra parameters captured by **kwargs will be passed to\n",
    "    pairwise_kernels() as kernel parameters. E.g. if\n",
    "    kernel_two_sample_test(..., kernel_function='rbf', gamma=0.1),\n",
    "    then this will result in getting the kernel through\n",
    "    kernel_function(metric='rbf', gamma=0.1).\n",
    "    \"\"\"\n",
    "\n",
    "    K = pairwise_kernels(Y, metric=kernel_function, **kwargs)\n",
    "    mmd2u = MMD2u(K, w, m, n)\n",
    "    if verbose:\n",
    "        print(\"MMD^2_u = %s\" % mmd2u)\n",
    "        print(\"Computing the null distribution.\")\n",
    "\n",
    "    mmd2u_null = compute_null_distribution(K, w, m, n, iterations,\n",
    "                                           verbose=verbose,\n",
    "                                           random_state=random_state)\n",
    "    #p_value = max(1.0/iterations, (mmd2u_null > mmd2u).sum() /\n",
    "    #              float(iterations))\n",
    "    p_value = np.mean(mmd2u_null > mmd2u)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"p-value ~= %s \\t (resolution : %s)\" % (p_value, 1.0/iterations))\n",
    "\n",
    "    return mmd2u, mmd2u_null, p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100\n",
    "n = 100\n",
    "\n",
    "pi_propensities = pi.get_propensities(X[:m], logging_T[:m])\n",
    "pi_prime_propensities = pi_prime.get_propensities(X[m:], logging_T[m:])\n",
    "\n",
    "estimate_logging_propensities = EstimatedLoggingPolicy(X, logging_T).get_propensities(X, logging_T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.concatenate([pi_propensities, pi_prime_propensities])[:, np.newaxis]/estimate_logging_propensities[:, np.newaxis]\n",
    "\n",
    "Y = logging_Y[:,np.newaxis]\n",
    "\n",
    "mmd2u, mmd2u_null, p_value = kernel_two_sample_test_nonuniform(Y, w, m, n, kernel_function='rbf', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def xMMD2(XY, T, w, kernel_function, **kwargs):\n",
    "#     \"\"\"The IPW-xKTE^2 statistic.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     N = len(XY)\n",
    "#     N2 = N//2\n",
    "    \n",
    "#     Ta = T[:N2]\n",
    "#     Tb = T[N2:]\n",
    "    \n",
    "#     Ya = XY[:N2]\n",
    "#     Yb = XY[N2:]\n",
    "#     Y0a = Ya[T[:N2]==0]\n",
    "#     Y1a = Ya[T[:N2]==1]\n",
    "#     Y0b = Yb[T[N2:]==0]\n",
    "#     Y1b = Yb[T[N2:]==1]\n",
    "#     Y = np.vstack((Y0a, Y1a, Y0b, Y1b))\n",
    "       \n",
    "#     wa = w.squeeze()[:N2]\n",
    "#     wb = w.squeeze()[N2:]\n",
    "#     w0a = 1.0/np.array(1 - wa[Ta==0])\n",
    "#     w0b = 1.0/np.array(1 - wb[Tb==0])\n",
    "#     w1a = 1.0/np.array(wa[Ta==1])\n",
    "#     w1b = 1.0/np.array(wb[Tb==1])\n",
    "#     ww = np.concatenate((-w0a, w1a, -w0b, w1b))\n",
    "\n",
    "    \n",
    "#     # IPW\n",
    "#     left_side = np.diag(ww[:N2])\n",
    "#     right_side = np.diag(ww[N2:])\n",
    "    \n",
    "#     KY = pairwise_kernels(Y[:N2], Y[N2:], metric=kernel_function, **kwargs)\n",
    "#     prod = left_side.T @ KY @ right_side\n",
    "    \n",
    "#     U = prod.mean(1)\n",
    "#     return np.sqrt(len(U)) * U.mean() / U.std()\n",
    "\n",
    "\n",
    "def xMMD2dr(Y, w, X, logging_T, kernel_function, **kwargs):\n",
    "    \n",
    "    \"\"\"The DR-xKTE^2 statistic.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    w_pi = w[:m]\n",
    "    w_pi_prime = w[m:]\n",
    "    # K_pi = np.outer(w_pi,w_pi)*K[:m, :m]\n",
    "    # K_pi_prime = np.outer(w_pi_prime,w_pi_prime)*K[m:, m:]  \n",
    "    \n",
    "    # N = len(XY)\n",
    "    # N2 = N//2\n",
    "    \n",
    "    m2 = m//2\n",
    "    w_pi_split1 = w_pi[:m2]\n",
    "    w_pi_split2 = w_pi[m2:]\n",
    "\n",
    "    n2 = n//2\n",
    "    w_pi_prime_split1 = w_pi_prime[:n2]\n",
    "    w_pi_prime_split2 = w_pi_prime[n2:]\n",
    "\n",
    "    # Ta = T[:N2]\n",
    "    # Tb = T[N2:]\n",
    "    \n",
    "\n",
    "    T_pi = T[:m]\n",
    "    T_pi_split1 = T_pi[:m2]\n",
    "    T_pi_split2 = T_pi[m2:]\n",
    "\n",
    "    T_pi_prime = T[m:]\n",
    "    T_pi_prime_split1 = T_pi_prime[:n2]\n",
    "    T_pi_prime_split2 = T_pi_prime[n2:]\n",
    "\n",
    "    T_ope = np.vstack((T_pi_split1, T_pi_prime_split1, T_pi_split2, T_pi_prime_split2))\n",
    "\n",
    "    Y_pi = Y[:m]\n",
    "    Y_pi_split1 = Y_pi[:m2]\n",
    "    Y_pi_split2 = Y_pi[m2:]\n",
    "\n",
    "    Y_pi_prime = Y[m:]\n",
    "    Y_pi_prime_split1 = Y_pi_prime[:n2]\n",
    "    Y_pi_prime_split2 = Y_pi_prime[n2:]\n",
    "    \n",
    "    # Ya = XY[:N2]\n",
    "    # Yb = XY[N2:]\n",
    "    # Y0a = Ya[T[:N2]==0]\n",
    "    # Y1a = Ya[T[:N2]==1]\n",
    "    # Y0b = Yb[T[N2:]==0]\n",
    "    # Y1b = Yb[T[N2:]==1]\n",
    "    # Y = np.vstack((Y0a, Y1a, Y0b, Y1b))\n",
    "    Y_ope = np.vstack((Y_pi_split1, Y_pi_prime_split1, Y_pi_split2, Y_pi_prime_split2))\n",
    "    # m1 = len(Y0a)\n",
    "    # m = m1 + len(Y0b)\n",
    "    # n1 = len(Y1a)\n",
    "    # n = n1 + len(Y1b)\n",
    "    \n",
    "    # X_split1 =  Xcov[:N2,:]\n",
    "    X_pi = X[:m, :]\n",
    "    X_pi_split1 = X_pi[:m2, :]\n",
    "    X_pi_split2 = X_pi[m2:, :]\n",
    "    X_pi_prime = X[m:, :]\n",
    "    X_pi_prime_split1 = X_pi_prime[:n2, :]\n",
    "    X_pi_prime_split2 = X_pi_prime[n2:, :]\n",
    "    # Xa = Xcov[:N2,:]\n",
    "    # Xb = Xcov[N2:,:]\n",
    "    # X0a = Xa[Ta==0, :]\n",
    "    # X0b = Xb[Tb==0, :]\n",
    "    # X1a = Xa[Ta==1, :]\n",
    "    # X1b = Xb[Tb==1, :]\n",
    "    # X = np.vstack((X0a, X1a, X0b, X1b))\n",
    "    \n",
    "    X_ope = np.vstack((X_pi_split1, X_pi_prime_split1, X_pi_split2, X_pi_prime_split2))\n",
    "\n",
    "    # wa = w.squeeze()[:N2]\n",
    "    # wb = w.squeeze()[N2:]\n",
    "    # w0a = 1.0/np.array(1 - wa[Ta==0])\n",
    "    # w0b = 1.0/np.array(1 - wb[Tb==0])\n",
    "    # w1a = 1.0/np.array(wa[Ta==1])\n",
    "    # w1b = 1.0/np.array(wb[Tb==1])\n",
    "    # ww = np.concatenate((-w0a, w1a, -w0b, w1b))\n",
    "    w_ope = np.concatenate((-w_pi_split1, w_pi_prime_split1, -w_pi_split2, w_pi_prime_split2))\n",
    "    \n",
    "    # sigmaKX = np.median(pairwise_distances(X[N2:, :], X[N2:, :], metric='euclidean'))**2\n",
    "    sigmaKX = np.median(pairwise_distances(X_ope[(m2+n2):, :], X_ope[(m2+n2):, :], metric='euclidean'))**2\n",
    "\n",
    "    sigmaKT = np.median(pairwise_distances(T_ope[(m2+n2):, :], T_ope[(m2+n2):, :], metric='euclidean'))**2\n",
    "    KX = pairwise_kernels(X_ope, metric='rbf', gamma=1.0/sigmaKX) \n",
    "    gamma = sigmaKX\n",
    "    \n",
    "    mu_pi_split1 = np.linalg.solve(KX[:m2, :m2] + gamma * np.eye(m2), KX[:m2, :m2+n2])\n",
    "\n",
    "    # mu0a = np.linalg.solve(KX[:m1, :m1] + gamma * np.eye(m1), KX[:m1, :m1+n1])\n",
    "    # zeroed_mu0a = np.vstack((mu0a, np.zeros((n1, m1+n1))))\n",
    "    zeroed_mu_pi_split1 = np.vstack((mu_pi_split1, np.zeros((n2, m2+n2))))\n",
    "\n",
    "    mu1a = np.linalg.solve(KX[m1:m1+n1, m1:m1+n1] + gamma * np.eye(n1), KX[m1:m1+n1, :m1+n1])\n",
    "    zeroed_mu1a = np.vstack(( np.zeros((m1, m1+n1)), mu1a ))    \n",
    "    muAa = np.hstack((zeroed_mu0a[:, :m1], zeroed_mu1a[:, m1:m1+n1]))\n",
    "    \n",
    "    mu0b = np.linalg.solve(KX[m1+n1:m+n1, m1+n1:m+n1] + gamma * np.eye(m-m1), KX[m1+n1:m+n1, m1+n1:])\n",
    "    zeroed_mu0b = np.vstack((mu0b, np.zeros((n-n1,m+n-m1-n1))))\n",
    "    mu1b = np.linalg.solve(KX[m+n1:, m+n1:] + gamma * np.eye(n-n1), KX[m+n1:, m1+n1:])\n",
    "    zeroed_mu1b = np.vstack((np.zeros((m-m1,m+n-m1-n1)), mu1b))\n",
    "    muAb = np.hstack((zeroed_mu0b[:, :m-m1], zeroed_mu1b[:, m-m1:]))\n",
    "    \n",
    "    \n",
    "    #DR\n",
    "    left_side = zeroed_mu1a - zeroed_mu0a + ww[:N2]*(np.eye(m1+n1) - muAa)\n",
    "    right_side = zeroed_mu1b - zeroed_mu0b + ww[N2:]*(np.eye(m+n-m1-n1) - muAb)\n",
    "    \n",
    "    \n",
    "    KY = pairwise_kernels(Y[:N2], Y[N2:], metric=kernel_function, **kwargs)\n",
    "    prod = left_side.T @ KY @ right_side\n",
    "    \n",
    "    U = prod.mean(1)\n",
    "    return np.sqrt(len(U)) * U.mean() / U.std()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def kernel_two_sample_test_agnostic(Y, T, w, kernel_function='rbf', p=0.5,\n",
    "#                            verbose=False, random_state=None, **kwargs):\n",
    "#     \"\"\"Compute the statistic IPW-xKTE and its p-value given normal distribution.\n",
    "#     \"\"\"\n",
    "#     xmmd2 = xMMD2(Y, T, w, kernel_function, **kwargs)\n",
    "#     if verbose:\n",
    "#         print(\"xMMD^2 = %s\" % xmmd2)\n",
    "#     p_value = 1 - st.norm.cdf(xmmd2)\n",
    "#     return xmmd2, p_value\n",
    "\n",
    "\n",
    "def kernel_dr_two_sample_test_agnostic(Y, Xcov, T, w, kernel_function='rbf', p=0.5,\n",
    "                           verbose=False, random_state=None, **kwargs): \n",
    "    \"\"\"Compute the statistic AIPW-xKTE and its p-value given normal distribution.\n",
    "    \"\"\" \n",
    "    xmmd2dr = xMMD2dr(Y, w, Xcov, T, kernel_function, **kwargs)\n",
    "    if verbose:\n",
    "        print(\"DR xMMD^2 = %s\" % xmmd2dr)\n",
    "    p_value = 1 - st.norm.cdf(xmmd2dr)\n",
    "    return xmmd2dr, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y[:,np.newaxis]\n",
    "YY0 = Y[T==0]\n",
    "YY1 = Y[T==1]\n",
    "YY0 = YY0[:,np.newaxis]\n",
    "YY1 = YY1[:,np.newaxis]\n",
    "\n",
    "# Gaussian RBF kernel\n",
    "sigma2 = np.median(pairwise_distances(YY0, YY1, metric='euclidean'))**2\n",
    "    \n",
    "if method == 'DR-xKTE':\n",
    "    t0 = time.time()\n",
    "    value, p_value = kernel_dr_two_sample_test_agnostic(Y, X, T, w,\n",
    "                                                        kernel_function='rbf',\n",
    "                                                        gamma=1.0/sigma2,\n",
    "                                                        verbose=False)\n",
    "    times[n] = time.time() - t0\n",
    "    p_values[n] = p_value\n",
    "    values[n] = value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gatsby",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
