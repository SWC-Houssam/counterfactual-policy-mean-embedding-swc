{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98f8a8b5-65a8-4647-bb15-b8509335a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from filelock import FileLock\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "sys.path.append(\"..\")\n",
    "# %%\n",
    "# DATA_PATH = pathlib.Path(__file__).resolve().parent.parent.joinpath(\"testing/dsprite\")\n",
    "DATA_PATH = Path(\"../testing/dsprite\")\n",
    "\n",
    "def load_dsprite_dataset():\n",
    "    with FileLock(\"./data.lock\"):\n",
    "        dataset_zip = np.load(\n",
    "            DATA_PATH.joinpath(\"dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz\"),\n",
    "            allow_pickle=True,\n",
    "            encoding=\"bytes\",\n",
    "        )\n",
    "    imgs = dataset_zip[\"imgs\"]\n",
    "    metadata = dataset_zip[\"metadata\"][()]\n",
    "    latents_sizes = metadata[b\"latents_sizes\"]\n",
    "    latents_bases = np.concatenate(\n",
    "        (latents_sizes[::-1].cumprod()[::-1][1:], np.array([1]))\n",
    "    )\n",
    "    return imgs, latents_bases\n",
    "\n",
    "\n",
    "def image_id(latent_bases, posX_id_arr, posY_id_arr):\n",
    "    data_size = posX_id_arr.shape[0]\n",
    "    color_id_arr = np.zeros(data_size, dtype=int)\n",
    "    shape_id_arr = np.full(data_size, 2, dtype=int)\n",
    "    scale_id_arr = np.zeros(data_size, dtype=int)\n",
    "    orientation_id_arr = np.zeros(data_size, dtype=int)\n",
    "    indices = np.stack(\n",
    "        [\n",
    "            color_id_arr,\n",
    "            shape_id_arr,\n",
    "            scale_id_arr,\n",
    "            orientation_id_arr,\n",
    "            posX_id_arr,\n",
    "            posY_id_arr,\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    return indices.dot(latent_bases)\n",
    "\n",
    "\n",
    "def structured_outcome_with_mixture_contrast(image: np.ndarray, low=0.5, high=1.5, rng=None) -> np.ndarray:\n",
    "    if rng is None:\n",
    "        rng = np.random.RandomState()\n",
    "    scale = rng.choice([low, high])\n",
    "    return scale * image\n",
    "\n",
    "\n",
    "class GaussianPolicy2D:\n",
    "    def __init__(self, theta=0.0, beta=0.0, sigma=0.1):\n",
    "        self.theta = theta\n",
    "        self.beta = beta\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def get_mean(self, U):\n",
    "        mean1 = U[:, 0] * np.cos(self.theta) + self.beta\n",
    "        mean2 = U[:, 1] * np.sin(self.theta) + self.beta\n",
    "        return np.stack([mean1, mean2], axis=1)\n",
    "\n",
    "    def sample_treatments(self, U):\n",
    "        mean = self.get_mean(U)\n",
    "        noise = np.random.normal(0, self.sigma, size=mean.shape)\n",
    "        return mean + noise\n",
    "\n",
    "    def get_propensities(self, U, A):\n",
    "        mean = self.get_mean(U)\n",
    "        diff = A - mean\n",
    "        norm_sq = np.sum(diff**2, axis=1)\n",
    "        d = A.shape[1]\n",
    "        return (1 / ((2 * np.pi * self.sigma**2) ** (d / 2))) * np.exp(\n",
    "            -norm_sq / (2 * self.sigma**2)\n",
    "        )\n",
    "\n",
    "\n",
    "def generate_logging_data(n, theta=0.0, beta=0.0, sigma=0.1, seed=0):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    U = rng.uniform(0, 1, size=(n, 2))\n",
    "    logging_policy = GaussianPolicy2D(theta, beta, sigma)\n",
    "    A = logging_policy.sample_treatments(U)\n",
    "    return U, A, logging_policy\n",
    "\n",
    "\n",
    "def generate_outcomes(U, A, imgs, latents_bases, rng=None, scenario=None):\n",
    "    posX = np.clip(((U[:, 0] + 1.5) * 32 / 3).astype(int), 0, 31)\n",
    "    posY = np.clip(((U[:, 1] + 1.5) * 32 / 3).astype(int), 0, 31)\n",
    "    image_indices = image_id(latents_bases, posX, posY)\n",
    "\n",
    "    if rng is None:\n",
    "        rng = np.random.RandomState()\n",
    "\n",
    "    Y = []\n",
    "    for idx in image_indices:\n",
    "        img = imgs[idx].astype(np.float32)\n",
    "        if scenario == \"III\":\n",
    "            img = structured_outcome_with_mixture_contrast(img, rng=rng)\n",
    "        Y.append(img)\n",
    "    return np.stack(Y, axis=0)\n",
    "\n",
    "\n",
    "def generate_ope_data(U, A, Y, logging_policy, pi, pi_prime, clip_value=1e5):\n",
    "    pi_density = pi.get_propensities(U, A)\n",
    "    pi_prime_density = pi_prime.get_propensities(U, A)\n",
    "    logging_density = logging_policy.get_propensities(U, A)\n",
    "\n",
    "    w_pi = np.clip(pi_density / logging_density, 0, clip_value)[:, None]\n",
    "    w_pi_prime = np.clip(pi_prime_density / logging_density, 0, clip_value)[:, None]\n",
    "\n",
    "    pi_samples = pi.sample_treatments(U)\n",
    "    pi_prime_samples = pi_prime.sample_treatments(U)\n",
    "\n",
    "    return dict(\n",
    "        U=U,\n",
    "        A=A,\n",
    "        Y=Y,\n",
    "        w_pi=w_pi,\n",
    "        w_pi_prime=w_pi_prime,\n",
    "        pi_samples=pi_samples,\n",
    "        pi_prime_samples=pi_prime_samples,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "792010a1-c17c-4881-a827-20376d70e278",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_base = 0.0\n",
    "beta_base = 0.0\n",
    "sigma = 0.01\n",
    "pi = GaussianPolicy2D(theta=theta_base, beta=beta_base + 0.5, sigma=sigma)\n",
    "pi_prime = GaussianPolicy2D(theta=theta_base, beta=beta_base - 0.5, sigma=sigma)\n",
    "\n",
    "imgs, latents_bases = load_dsprite_dataset()\n",
    "n = 100\n",
    "rng = np.random.RandomState(0)\n",
    "U = rng.uniform(0, 1, size=(n, 2))\n",
    "logging_policy = pi\n",
    "A_log = logging_policy.sample_treatments(U)\n",
    "Y_log = generate_outcomes(U, A_log, imgs, latents_bases, rng=rng)\n",
    "target_policy = pi_prime\n",
    "A_tgt = target_policy.sample_treatments(U)\n",
    "Y_tgt = generate_outcomes(U, A_tgt, imgs, latents_bases, rng=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67c9a4c1-082b-483e-8d24-f2b0274336a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "from scipy.stats import wasserstein_distance\n",
    "from sklearn.metrics import pairwise_kernels, pairwise_distances\n",
    "import os\n",
    "from scipy.optimize import minimize\n",
    "# from embeddings import plugin_embedding_pi, dr_embedding_pi, mmd2_biased, mmd2_unbiased\n",
    "from environment import (\n",
    "    logistic_logging_policy,\n",
    "    reward_nonlinear,\n",
    "    reward_quadratic,\n",
    "    find_best_params,\n",
    "    importance_weights,\n",
    "    pi0_proba,\n",
    "    pi_proba,\n",
    ")\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a635e09-c3c2-456c-9f8c-6146c67b5b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plugin_embedding_pi(\n",
    "    Y, X, logging_T, pi_samples, reg_lambda, sigmaKX=1.0, sigmaKT=0.5\n",
    "):\n",
    "    N = len(Y)\n",
    "    KX = pairwise_kernels(X, metric=\"rbf\", gamma=1.0 / (sigmaKX))\n",
    "    KT = pairwise_kernels(logging_T, metric=\"rbf\", gamma=1.0 / (sigmaKT))\n",
    "    KT_pi = pairwise_kernels(\n",
    "        logging_T, pi_samples, metric=\"rbf\", gamma=1.0 / (sigmaKT)\n",
    "    )\n",
    "    print(KX.shape, KT.shape, KT_pi.shape)\n",
    "    mu_pi = np.linalg.solve(\n",
    "        np.multiply(KX, KT) + reg_lambda * np.eye(N), np.multiply(KX, KT_pi)\n",
    "    )\n",
    "    return mu_pi\n",
    "\n",
    "def dr_embedding_pi(\n",
    "    Y, X, logging_T, w_pi, pi_samples, reg_lambda, sigmaKX=1.0, sigmaKT=0.5\n",
    "):\n",
    "    N = len(Y)\n",
    "    KX = pairwise_kernels(X, metric=\"rbf\", gamma=1.0 / (sigmaKX))\n",
    "    KT = pairwise_kernels(logging_T, metric=\"rbf\", gamma=1.0 / (sigmaKT))\n",
    "    KT_pi = pairwise_kernels(\n",
    "        logging_T, pi_samples, metric=\"rbf\", gamma=1.0 / (sigmaKT)\n",
    "    )\n",
    "    mu_log = np.linalg.solve(\n",
    "        np.multiply(KX, KT) + reg_lambda * np.eye(N), np.multiply(KX, KT)\n",
    "    )\n",
    "    mu_pi = np.linalg.solve(\n",
    "        np.multiply(KX, KT) + reg_lambda * np.eye(N), np.multiply(KX, KT_pi)\n",
    "    )\n",
    "    phi = mu_pi + w_pi[:, None] * (np.eye(N) - mu_log)\n",
    "    return phi\n",
    "\n",
    "\n",
    "def kernel_herding(Y_support, weights, sigma, num_samples):\n",
    "    y0 = np.random.randn(Y_support.shape[1])\n",
    "    res = minimize(\n",
    "        lambda y: -np.mean(\n",
    "            np.dot(\n",
    "                weights.T,\n",
    "                pairwise_kernels(\n",
    "                    Y_support,\n",
    "                    np.atleast_2d(y),\n",
    "                    metric=\"rbf\",\n",
    "                    gamma=1.0 / (2 * sigma),\n",
    "                ),\n",
    "            )\n",
    "        ),\n",
    "        y0,\n",
    "        method=\"CG\",\n",
    "        options={\"gtol\": 1e-6, \"disp\": False},\n",
    "    )\n",
    "    yt = res.x.ravel()\n",
    "\n",
    "    samples = [yt]\n",
    "    for t in tqdm(range(2, num_samples + 1)):\n",
    "        yt_hist = np.array(samples)\n",
    "        res = minimize(\n",
    "            lambda y: -np.mean(\n",
    "                np.dot(\n",
    "                    weights.T,\n",
    "                    pairwise_kernels(\n",
    "                        Y_support,\n",
    "                        np.atleast_2d(y),\n",
    "                        metric=\"rbf\",\n",
    "                        gamma=1.0 / (2 * sigma),\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "            + np.mean(\n",
    "                pairwise_kernels(\n",
    "                    yt_hist,\n",
    "                    np.atleast_2d(y),\n",
    "                    metric=\"rbf\",\n",
    "                    gamma=1.0 / (2 * sigma),\n",
    "                )\n",
    "            ),\n",
    "            y0,\n",
    "            method=\"CG\",\n",
    "            options={\"gtol\": 1e-6, \"disp\": False},\n",
    "        )\n",
    "        yt = res.x.ravel()\n",
    "        samples.append(yt)\n",
    "    return np.array(samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b0a5fa-ae00-4bf4-8186-54cc74ca27eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100) (100, 100) (100, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 23/24 [03:27<00:09,  9.42s/it]"
     ]
    }
   ],
   "source": [
    "# Importance weights\n",
    "w_pi = importance_weights(A_log, U, pi_prime.get_propensities, pi.get_propensities)\n",
    "X_log = U\n",
    "# Regularization and kernel params\n",
    "reg_lambda = 1e-5\n",
    "sigmaKX = np.median(pairwise_distances(X_log)) ** 2 + 1e-8\n",
    "sigma = np.median(pairwise_distances(Y_log.reshape(n, -1))) ** 2 + 1e-8\n",
    "\n",
    "# # Embedding and kernel herding\n",
    "phi_plugin = plugin_embedding_pi(Y_log.reshape(n, -1), X_log, A_log, A_tgt, reg_lambda, sigmaKX)\n",
    "# phi_dr = dr_embedding_pi(Y_log.reshape(n, -1), X_log, A_log, w_pi, A_tgt, reg_lambda, sigmaKX)\n",
    "Y_plugin = kernel_herding(Y_log.reshape(n, -1), phi_plugin, sigma, 25)\n",
    "# Y_dr = kernel_herding(Y_log.reshape(n, -1), phi_dr, sigma, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c054fe2b-ef65-4668-bb7f-c5714f770340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(Y_plugin[-1].reshape(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c1a10d-6bd5-4806-874c-726632153af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi.get_propensities(A_log, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf497172-2527-409f-b9db-bc9e9d7abc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_log.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ae1162-ad67-46d1-bc81-12ae611880c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_plugin.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
